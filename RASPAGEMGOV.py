# -*- coding: utf-8 -*-
"""RASPAGEMGOV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jr2HUjfRVVywfXDFgC3CcwEbfWppNZjm

# Preparando
"""

import os
import json
import gspread
from google.oauth2.service_account import Credentials
import requests
from bs4 import BeautifulSoup
from datetime import datetime

def initialize_sheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = Credentials.from_service_account_info(json.loads(os.environ['GOOGLE_APPLICATION_CREDENTIALS_JSON']), scopes=scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(os.environ['SHEET_KEY']).sheet1
    return sheet

# Ministério do Esporte
def raspar_noticias_esporte(url, sheet, data_desejada=None):
    if data_desejada is None:
        data_desejada = datetime.now().strftime("%d/%m/%Y")  # Formato de data: DD/MM/YYYY
    response = requests.get(url)
    html_content = response.text
    soup = BeautifulSoup(html_content, 'html.parser')
    meta_tag = soup.find('meta', property="og:site_name")
    nome_ministerio = meta_tag['content'] if meta_tag else "Nome do Ministério não identificado"
    noticias = soup.find_all('li')
    for noticia in noticias:
        data = noticia.find('span', class_='data')
        if data and data.text.strip() == data_desejada:
            subtitulo = noticia.find('div', class_='subtitulo-noticia').text.strip()
            titulo = noticia.find('h2', class_='titulo').text.strip()
            descricao = noticia.find('span', class_='descricao')
            descricao_text = descricao.text.split('-')[1].strip() if '-' in descricao.text else descricao.text.strip()
            link = noticia.find('h2', class_='titulo').find('a')['href']
            dados = [data.text.strip(), nome_ministerio, subtitulo, titulo, descricao_text, link]
            sheet.append_row(dados)
    print('Dados do Esporte inseridos com sucesso na planilha.')

# Ministério da Educação
def raspar_noticias_educacao(url, sheet, data_desejada=None):
    response = requests.get(url)
    if response.status_code == 200:
        html_content = response.text
        soup = BeautifulSoup(html_content, 'html.parser')
        meta_tag = soup.find('meta', property="og:site_name")
        nome_ministerio = meta_tag['content'] if meta_tag else "Nome do Ministério não identificado"
        noticias = soup.find_all('li')
        for noticia in noticias:
            data = noticia.find('span', class_='data')
            if data and data.text.strip() == data_desejada:
                subtitulo = noticia.find('div', class_='subtitulo-noticia').text.strip()
                titulo = noticia.find('h2', class_='titulo').text.strip()
                descricao = noticia.find('span', class_='descricao')
                descricao_text = descricao.text.split('-')[1].strip() if '-' in descricao.text else descricao.text.strip()
                link = noticia.find('h2', class_='titulo').find('a')['href']
                dados = [data.text.strip(), nome_ministerio, subtitulo, titulo, descricao_text, link]
                sheet.append_row(dados)
        print('Dados da Educação inseridos com sucesso na planilha.')
    else:
        print(f"Erro ao acessar {url}, Status Code: {response.status_code}")

# Ministério da Saúde
def raspar_noticias_saude(url, data_desejada=None):
    sheet = initialize_sheet()
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        nome_ministerio_tag = soup.find('a', href="https://www.gov.br/saude/pt-br")
        nome_ministerio = nome_ministerio_tag.text.strip() if nome_ministerio_tag else "Nome do Ministério não disponível"
        noticias = soup.find_all('article', class_='tileItem')
        for noticia in noticias:
            data_icon = noticia.find('i', class_='icon-day')
            data = data_icon.find_next_sibling(string=True).strip() if data_icon else "Data não disponível"
            if data == data_desejada:
                subt = noticia.find('span', class_='subtitle')
                subtitulo = subt.text.strip() if subt else "Subtítulo não disponível"
                tit = noticia.find('h2', class_='tileHeadline').find('a')
                titulo = tit.text.strip() if tit else "Título não disponível"
                link = tit['href'] if tit else "Link não disponível"
                desc = noticia.find('span', class_='description')
                descricao = desc.text.strip() if desc else "Descrição não disponível"
                sheet.append_row([data, nome_ministerio, subtitulo, titulo, descricao, link])
        print('Dados da Saúde inseridos com sucesso na planilha.')
    else:
        print(f"Erro ao acessar {url}, Status Code: {response.status_code}")

# Definir as variáveis de ambiente e as URLs dos ministérios
if __name__ == "__main__":
    sheet = initialize_sheet()
    raspar_noticias_esporte("https://www.gov.br/esporte/pt-br/noticias-e-conteudos/esporte", sheet)
    raspar_noticias_educacao("https://www.gov.br/mec/pt-br/assuntos/noticias", sheet)
    raspar_noticias_saude("https://www.gov.br/saude/pt-br/assuntos/noticias")
